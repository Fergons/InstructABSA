{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Term Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  cab ride, service\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/ate_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruction = \"\"\"Definition: The output will be the aspects (both implicit and explicit) which have an associated opinion that are extracted from the input text. In cases where there are no aspects the output should be noaspectterm.\n",
    "    Positive example 1-\n",
    "    input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
    "    output: battery life\n",
    "    Positive example 2-\n",
    "    input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!.\n",
    "    output: features, iChat, Photobooth, garage band\n",
    "    Negative example 1-\n",
    "    input: Speaking of the browser, it too has problems.\n",
    "    output: browser\n",
    "    Negative example 2-\n",
    "    input: The keyboard is too slick.\n",
    "    output: keyboard\n",
    "    Neutral example 1-\n",
    "    input: I took it back for an Asus and same thing- blue screen which required me to remove the battery to reset.\n",
    "    output: battery\n",
    "    Neutral example 2-\n",
    "    input: Nightly my computer defrags itself and runs a virus scan.\n",
    "    output: virus scan\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = 'The cab ride was amazing but the service was pricey.'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect Term Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output for cab ride:  positive\n",
      "Model output for driver:  negative\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/atsc_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/atsc_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruct = \"\"\"Definition: The output will be 'positive' if the aspect identified in the sentence contains a positive sentiment. If the sentiment of the identified aspect in the input is negative the answer will be 'negative'. \n",
    "    Otherwise, the output should be 'neutral'. For aspects which are classified as noaspectterm, the sentiment is none.\n",
    "    Positive example 1-\n",
    "    input: With the great variety on the menu , I eat here often and never get bored. The aspect is menu.\n",
    "    output: positive\n",
    "    Positive example 2- \n",
    "    input: Great food, good size menu, great service and an unpretensious setting. The aspect is food.\n",
    "    output: positive\n",
    "    Negative example 1-\n",
    "    input: They did not have mayonnaise, forgot our toast, left out ingredients (ie cheese in an omelet), below hot temperatures and the bacon was so over cooked it crumbled on the plate when you touched it. The aspect is toast.\n",
    "    output: negative\n",
    "    Negative example 2-\n",
    "    input: The seats are uncomfortable if you are sitting against the wall on wooden benches. The aspect is seats.\n",
    "    output: negative\n",
    "    Neutral example 1-\n",
    "    input: I asked for seltzer with lime, no ice. The aspect is seltzer with lime.\n",
    "    output: neutral\n",
    "    Neutral example 2-\n",
    "    input: They wouldnt even let me finish my glass of wine before offering another. The aspect is glass of wine.\n",
    "    output: neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ' The aspect is '\n",
    "eos_instruct = '.\\noutput:'\n",
    "text = 'The cab ride was amazing but the driver was rude.'\n",
    "aspect_term = 'cab ride'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + aspect_term + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print(f'Model output for {aspect_term}: ', tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "aspect_term = 'driver'\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + aspect_term + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print(f'Model output for {aspect_term}: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Task - Aspect Term and Polarity Co Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.57k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c073b5eef28c4169bff7d09a20e8c826"
      },
      "application/json": {
       "n": 0,
       "total": 2571,
       "elapsed": 0.005063533782958984,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba234d2a31d648d699eec4733672fa30"
      },
      "application/json": {
       "n": 0,
       "total": 791656,
       "elapsed": 0.008107185363769531,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.42M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6069de9113664485a81dbe5ac07ce57b"
      },
      "application/json": {
       "n": 0,
       "total": 2422261,
       "elapsed": 0.005925416946411133,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/2.20k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53f2e9bc9b304b7a91b11c4675f85e94"
      },
      "application/json": {
       "n": 0,
       "total": 2201,
       "elapsed": 0.0055522918701171875,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/776 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "987cd0e0ae28445ba23a96589a02041c"
      },
      "application/json": {
       "n": 0,
       "total": 776,
       "elapsed": 0.0054590702056884766,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/990M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e13521ad7c36487f80291949c81bace0"
      },
      "application/json": {
       "n": 0,
       "total": 990236853,
       "elapsed": 0.006188631057739258,
       "ncols": null,
       "nrows": null,
       "prefix": "Downloading",
       "ascii": false,
       "unit": "B",
       "unit_scale": true,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  cab ride:positive, service:negative\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined\")\n",
    "\n",
    "bos_instruction = \"\"\"Definition: The output will be the aspects (both implicit and explicit) and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspectterm:none.\n",
    "    Positive example 1-\n",
    "    input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
    "    output: battery life:positive, \n",
    "    Positive example 2-\n",
    "    input: I even got my teenage son one, because of the features that it offers, like, iChat, Photobooth, garage band and more!.\n",
    "    output: features:positive, iChat:positive, Photobooth:positive, garage band:positive\n",
    "    Negative example 1-\n",
    "    input: Speaking of the browser, it too has problems.\n",
    "    output: browser:negative\n",
    "    Negative example 2-\n",
    "    input: The keyboard is too slick.\n",
    "    output: keyboard:negative\n",
    "    Neutral example 1-\n",
    "    input: I took it back for an Asus and same thing- blue screen which required me to remove the battery to reset.\n",
    "    output: battery:neutral\n",
    "    Neutral example 2-\n",
    "    input: Nightly my computer defrags itself and runs a virus scan.\n",
    "    output: virus scan:neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = 'The cab ride was amazing but the service was pricey.'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  noaspectterm:category:polarity\n"
     ]
    }
   ],
   "source": [
    "bos_instruction = \"\"\"Definition: The output will be the aspect terms, the aspects and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspect:none:none. In cases where there are no aspect terms the output for the term value should be noaspectterm.\n",
    "    Positive example 1-\n",
    "    input: Grafika je na úrovni, hra je pěkně zpracovaná a příběh je zajímavý.\n",
    "    output: grafika:audio_visuals:positive, noaspectterm:performance_bugs:positive, příběh:story:positive\n",
    "    Positive example 2-\n",
    "    input: Hra má pěknou grafiku, příjemný zvuk a pohodlné ovládání.\n",
    "    output: grafika:audio_visuals:positive, zvuk:audio_visuals:positive, ovládání:gameplay:positive\n",
    "    Negative example 1-\n",
    "    input: Hra má několik velkých nedostatků, které ji značně omezují jako například nízká rozlišení, špatný zvuk a nepříjemné ovládání.\n",
    "    output: rozlišení:audio_visuals:negative, zvuk:audio_visuals:negative, ovládání:gameplay:negative\n",
    "    Negative example 2-\n",
    "    input: Postavy jsou nevýrazné, grafika je špatná a hra je nesmyslná.\n",
    "    output: postavy:story:negative, grafika:audio_visuals:negative, hra:overall:negative\n",
    "    Neutral example 1-\n",
    "    input: Hra není úplne k zahození, ale nejde o žádnou hru, která by byla nějakým zázrakem.\n",
    "    output: hra:overall:neutral\n",
    "    Neutral example 2-\n",
    "    input: The game has multiplayer.\n",
    "    output: multiplayer:gameplay:neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = ''\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "249"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text.input_ids[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17396\\3532465.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAutoModelForSeq2SeqLM\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m bos_instruction = \"\"\"Definition: The output will be the aspect terms, the aspects and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspect:none:none. In cases where there are no aspect terms the output for the term value should be noaspectterm.\n\u001B[0;32m      5\u001B[0m     \u001B[0mPositive\u001B[0m \u001B[0mexample\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PythonProjects\\SentimentAnalysis\\venv2\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[0;32m    580\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    581\u001B[0m         \u001B[1;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 582\u001B[1;33m         \u001B[0mtokenizer_config\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_tokenizer_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    583\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;34m\"_commit_hash\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtokenizer_config\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    584\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"_commit_hash\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer_config\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"_commit_hash\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PythonProjects\\SentimentAnalysis\\venv2\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\u001B[0m in \u001B[0;36mget_tokenizer_config\u001B[1;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001B[0m\n\u001B[0;32m    431\u001B[0m     ```\"\"\"\n\u001B[0;32m    432\u001B[0m     \u001B[0mcommit_hash\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"_commit_hash\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 433\u001B[1;33m     resolved_config_file = cached_file(\n\u001B[0m\u001B[0;32m    434\u001B[0m         \u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    435\u001B[0m         \u001B[0mTOKENIZER_CONFIG_FILE\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PythonProjects\\SentimentAnalysis\\venv2\\lib\\site-packages\\transformers\\utils\\hub.py\u001B[0m in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[0;32m    407\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m         \u001B[1;31m# Load from URL or cache if already cached\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m         resolved_file = hf_hub_download(\n\u001B[0m\u001B[0;32m    410\u001B[0m             \u001B[0mpath_or_repo_id\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m             \u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PythonProjects\\SentimentAnalysis\\venv2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\u001B[0m in \u001B[0;36m_inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m         ):\n\u001B[0;32m    113\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0marg_name\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"repo_id\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m                 \u001B[0mvalidate_repo_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marg_value\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0marg_name\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"token\"\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0marg_value\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PythonProjects\\SentimentAnalysis\\venv2\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\u001B[0m in \u001B[0;36mvalidate_repo_id\u001B[1;34m(repo_id)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mrepo_id\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"/\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 166\u001B[1;33m         raise HFValidationError(\n\u001B[0m\u001B[0;32m    167\u001B[0m             \u001B[1;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m             \u001B[1;34mf\" '{repo_id}'. Use `repo_type` argument if needed.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"D:/PythonProjects/SentimentAnalysis/src/InstructABSA/Models/allenaitk-instruct-base-def-pos-joint_ACSE\")\n",
    "\n",
    "bos_instruction = \"\"\"Definition: The output will be the aspect terms, the aspects and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspect:none:none. In cases where there are no aspect terms the output for the term value should be noaspectterm.\n",
    "    Positive example 1-\n",
    "    input: Grafika je na úrovni, hra je pěkně zpracovaná a příběh je zajímavý.\n",
    "    output: grafika:audio_visuals:positive, noaspectterm:performance_bugs:positive, příběh:story:positive\n",
    "    Positive example 2-\n",
    "    input: Hra má pěknou grafiku, příjemný zvuk a pohodlné ovládání.\n",
    "    output: grafika:audio_visuals:positive, zvuk:audio_visuals:positive, ovládání:gameplay:positive\n",
    "    Negative example 1-\n",
    "    input: Hra má několik velkých nedostatků, které ji značně omezují jako například nízká rozlišení, špatný zvuk a nepříjemné ovládání.\n",
    "    output: rozlišení:audio_visuals:negative, zvuk:audio_visuals:negative, ovládání:gameplay:negative\n",
    "    Negative example 2-\n",
    "    input: Postavy jsou nevýrazné, grafika je špatná a hra je nesmyslná.\n",
    "    output: postavy:story:negative, grafika:audio_visuals:negative, hra:overall:negative\n",
    "    Neutral example 1-\n",
    "    input: Hra není úplne k zahození, ale nejde o žádnou hru, která by byla nějakým zázrakem.\n",
    "    output: hra:overall:neutral\n",
    "    Neutral example 2-\n",
    "    input: The game has multiplayer.\n",
    "    output: multiplayer:gameplay:neutral\n",
    "    Now complete the following example-\n",
    "    input: \"\"\"\n",
    "delim_instruct = ''\n",
    "eos_instruct = ' \\noutput:'\n",
    "text = 'Super hra, ale grafika je špatná.'\n",
    "\n",
    "tokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\n",
    "output = model.generate(tokenized_text.input_ids)\n",
    "print('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basegpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
